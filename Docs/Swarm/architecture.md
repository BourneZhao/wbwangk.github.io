[原文](http://swarm-guide.readthedocs.io/en/latest/architecture.html)

# 架构

本章面向希望了解swarm的基本概念和设计的开发人员。

内容

- 建筑
  - swarm哈希
    - [介绍](http://swarm-guide.readthedocs.io/en/latest/architecture.html#introduction)
    - [描述](http://swarm-guide.readthedocs.io/en/latest/architecture.html#description)
    - [严格的解释](http://swarm-guide.readthedocs.io/en/latest/architecture.html#strict-interpretation)
    - [松散的解释](http://swarm-guide.readthedocs.io/en/latest/architecture.html#loose-interpretations)
  - [分块](http://swarm-guide.readthedocs.io/en/latest/architecture.html#chunker)
  - 分布式原像档案
    - [高层次的设计](http://swarm-guide.readthedocs.io/en/latest/architecture.html#high-level-design)
    - [要求](http://swarm-guide.readthedocs.io/en/latest/architecture.html#requests)
  - [同步](http://swarm-guide.readthedocs.io/en/latest/architecture.html#syncing)
  - 同行管理（蜂房，kademlia）
    - [对等地址](http://swarm-guide.readthedocs.io/en/latest/architecture.html#peer-addresses)
    - [对数距离和网络拓扑](http://swarm-guide.readthedocs.io/en/latest/architecture.html#logarithmic-distance-and-network-topology)
    - [对等表格格式](http://swarm-guide.readthedocs.io/en/latest/architecture.html#peer-table-format)
    - [对等表更新](http://swarm-guide.readthedocs.io/en/latest/architecture.html#peer-table-update)
  - [bzz协议](http://swarm-guide.readthedocs.io/en/latest/architecture.html#the-bzz-protocol)
  - Incentivisation
    - [swap，swar和swindle](http://swarm-guide.readthedocs.io/en/latest/architecture.html#swap-swear-swindle)
    - [SWAP - Swarm Accounting Protocol](http://swarm-guide.readthedocs.io/en/latest/architecture.html#swap-swarm-accounting-protocol)
    - [SWEAR - 具有强制存档规则或swarm执行和注册的存储](http://swarm-guide.readthedocs.io/en/latest/architecture.html#swear-storage-with-enforced-archiving-rules-or-swarm-enforcement-and-registration)
    - [SWINDLE - 由INSUANCE存款诉讼和托管担保](http://swarm-guide.readthedocs.io/en/latest/architecture.html#swindle-secured-with-insurance-deposit-litigation-and-escrow)

有4个不同层级的数据单元与swarm相关：

- *message*：p2p RLPx网络层。消息与bzz有线协议[bzz协议相关](http://swarm-guide.readthedocs.io/en/latest/architecture.html#the-bzz-protocol)。
- *chunk*：存储，内容寻址，请求/传送和记帐的固定大小数据单元：这是与整个存储层相关的级别（包括localStore，DHT/netstore，bzz协议，计费协议）
- *document*：为了获得更好的单词，我们称之为与mime类型关联的最小单元，除非它是完整的，否则不保证具有完整性。这是用户的最小单位语义，基本上是文件系统上的一个文件。该层由DPA及其Chunker处理。
- *collection*：由*swarm清单*表示的一个到文档的路径映射。此层级已映射到文件系统目录树。考虑到不重要的路由约定，url可以以标准化的方式映射到文档，允许清单模仿swarm中的web服务器。该层与高级别API相关：go API、HTTP代理API、控制台和web3 JS API。

swarm的实际存储层由两个主要组件组成，即*localstore（LOC）*和*netstore（NET）*。本地存储为用于存储的本地计算资源提供接口。特别是我们明确地描述了内存中的快速缓存（*内存存储（MEM）*）和持久性磁盘存储（可能具有其自己的缓存系统的*dbstore（DBS）*）。原因在于我们可以通过依赖于特定于我们目的的内存存储的某些属性来优化系统，例如，密钥是哈希，所以不需要进一步的哈希，密钥可以直接映射到树/树(tree/trie)结构体。

对于磁盘存储，使用leveldb。这两个组件都可以轻松地通过替代解决方案进行交换，而且工作量极小

netStore是实际的DHT（分布式哈希表）实现。它与bzz协议以及网络peer逻辑管理器配合使用。netStore确实是实施分布式存储逻辑的地方。

在*分布式原像归档（DPA）*是用于存储和检索文件的本地接口。将文档交给DPA进行存储时，它将文档分块成merkle哈希树并将其根键传回给调用者（DPA）。这个键以后可以用来部分或全部检索请求的文档。

将文档分成merkle树的组件称为*chunker*。我们的chunker实现了*bzzhash*算法，该算法是基于Keccak 256位SHA3的并行树结构。DPA运行一个存储循环，该循环接收来自chunker的组块，并将其分派到chunkstore进行存储。这个入口点是netStore。

当根键交给DPA进行文档检索时，DPA会呼叫将可搜索文档阅读器回传给调用者的Chunker。这是一个*懒惰的读者*，因为它只是在实际阅读时才检索底层文档的相关部分。这需要在最低级别上支持部分读取（例如视频范围请求）。换句话说，该方案提供了文档的完整性保护的随机存取存储。

swarm清单是一个定义了任意路径和文档到处理文档集合之间映射的结构。它还包括集合与集合内文档相关的各种元数据。

清单的高级API提供了将单个文档上载和下载为文件、集合（清单）作为目录的功能。它还提供了一个接口，用于将文档添加到路径上的集合中，从集合中删除文档。请注意，此处的删除仅表示创建了一个新的清单，其中删除了请求的路径。swarm中没有其他的删除概念。

API是这些高级功能的执行（和go API）。有一个http代理接口以及这些函数的RPC API。由于固有的特权差异或接口限制，这些都在其确切的功能上有所不同。这些在[使用](http://swarm-guide.readthedocs.io/en/latest/usage.html#usage)中有详细描述。

所述[SWAP -swarm计费协议](http://swarm-guide.readthedocs.io/en/latest/architecture.html#swap)组件跟踪peer之间的请求和实现计费协议。这在[激励措施](http://swarm-guide.readthedocs.io/en/latest/architecture.html#incentivisation)中有详细描述。

在下面我们更详细地描述组件。

## swarm哈希

### 介绍

Swarm哈希（亦称bzzhash）是一种[Merkle树]（<http://en.wikipedia.org/wiki/Merkle_tree>）哈希，用于在（本地和网络）内容寻址存储中进行高效存储和检索。虽然它在Swarm中使用，但其中并没有特定的Swarm特有的内容，作者建议将它用作顺序迭代哈希函数（如SHA3）的插入替换，无论何时用于引用对完整性敏感的内容，如它在性能和可用性方面进行了改进，而不会影响安全性。

特别是，它可以利用并行化（包括SMP和大规模并行架构，如GPU）来加速计算和验证，可用于验证部分内容的完整性，而无需传输全部内容。底层哈希函数的安全证明继承到Swarm哈希。

### 描述

Swarm哈希是使用常规哈希函数（在我们的例子中是Keccak 256位SHA3）与Merkle的树哈希方案的泛化构造的。哈希的基本单位是*块*，可以是包含要被哈希内容一部分的*叶子块*，也可以是包含子元素哈希的*内部块*，可以是多种类型的。

叶子块的哈希被定义为内容和内容本身的64位长度（LSB-first order）的级联哈希。由于包含了长度，它也可以抵抗[长度扩展攻击](<http://en.wikipedia.org/wiki/Length_extension_attack>)，即使底层哈希函数不是。请注意，此“安全带”措施广泛用于最新版[OpenPGP标准（IETF RFC4880）]（<https://tools.ietf.org/html/rfc4880>）。这就是说，swarm哈希仍然容易受到长度扩展攻击的影响，但是在必要时可以使用类似的更高层次的措施轻松防范。可能非常有利可图的性能优化（当前未实现）是使用标准块大小（例如4096字节）的长度来初始化哈希计算，从而节省其重复哈希。

内部块的哈希被定义为由植入在该块上的整个（sub-）树和其子元素的哈希所哈希的内容的64位长度（以LSB-first的顺序）串联的哈希。

为了区分这两者，应该将块的长度与每个块开始的64位数进行比较。如果块大小比这个数字长8个字节，它就是一个叶块。如果它比这短，它是一个内部块。否则，它不是有效的Swarm哈希块。

### 严格的解释

一个严格的Swarm哈希是一个可能例外的每个块，其中最右边的分支有一个特定的长度，即4千字节。那些在最右边的分支不再，但可能比这个长度更短。哈希树必须是平衡的，这意味着所有的根到叶分支具有相同的长度。

严格的解释是唯一的，因为只有一个哈希值与特定内容匹配。如果内容的长度是块大小的倍数，并且叶块的数量是分支大小的整数倍（固定最大块大小除以哈希长度），则严格解释仅容易受到长度扩展攻击的影响。

两个[已并行化的实现可在Go中找到]（<https://github.com/ethereum/go-ethereum/tree/develop/swarm/storage/>）以及[命令行工具]（[https：// github.com/ethereum/go-ethereum/tree/develop/cmd/bzzhash](https://github.com/ethereum/go-ethereum/tree/develop/cmd/bzzhash)）使用严格的解释来哈希本地文件系统上的文件。

### [松散的解释](http://swarm-guide.readthedocs.io/en/latest/architecture.html#id11)

swarm哈希解释不太严格可能允许不同的树结构，施加更少的限制或根本没有。通过这种方式，不同的哈希值可以解析为相同的内容，这可能会产生一些不利的安全隐患。

但是，它可能为不构成漏洞的不同应用打开大门。例如，除了严格的Swarm哈希之外，接受单叶哈希还允许引用文件而不必实现整个事情。

## [分块](http://swarm-guide.readthedocs.io/en/latest/architecture.html#id12)

*Chunker*是负责拆卸和组装大型数据的组件的接口。它依赖于基础分块模型。该模块是可插拔的，目前执行使用*Treechunker*它实现*bzzhash*。另一种实现方式是*金字塔形*块，它对于更大的数据更有效率，并且不需要文件的大小，所以原则上能够实时编码实时流。

当*拆分*文档时，chunker将产生的块推送给将它们委托给存储层（实现ChunkStore接口）的DPA，并返回文档的*根哈希*。在得到通知所有数据已被分割（错误通道关闭）之后，调用者可以安全地读取或保存根密钥。否则，如果不是所有的块都被存储或者没有处理完整个数据流，则超时。通过检查errc通道，调用者可以检查在分割过程中是否发生任何显式错误（通常是IO读/写失败）。

当*加入*一个文件，该组块需要的根密钥，并返回一个*懒惰的读者*。在加入时，chunker将块请求推送给将它们委托给块存储的DPA，并在数据已传递（即从内存缓存，磁盘持久数据库或基于云的swarm传递中检索到）的情况下通知分块器。然后chunker将这些文件放在需求上，并在阅读器上读取。

该chunker以一种简单的方式工作，它从文档中构建一棵树，以便每个节点代表一个真实数据块或表示树的分支非叶节点的一块数据。特别地，每个这样的非叶片块将表示其各自子代的哈希的串联。该方案同时保证数据完整性和自寻址。的*最大块大小*目前4096来自多个可配置参数：选项：分支和：选项：哈希。除了数据之外，块还包含它编码的子树的大小。抽象节点是透明的，因为它们表示的大小组件严格大于它们的最大数据大小，因为它们编码了一个子树。由于大小由64位整数（8字节）表示，因此块的存储大小至多为4104字节。

## [分布式原像档案](http://swarm-guide.readthedocs.io/en/latest/architecture.html#id13)

*DPA（分布式原像档案）*存储可通过它们的（密码）哈希值检索的小块信息（原像对象，有限长度的任意字节的字节）。因此，存储在DPA中的原像对象具有隐式完整性保护。假定用于密钥分配的哈希函数是无碰撞的，这意味着对于不同的原像对象的碰撞密钥实际上是不可能的。

DPA可作为快速冗余存储，为快速检索和长期可靠性而优化。由于密钥是从preimage派生的，所以我们没有办法在其中讨论多个或另一个密钥的值，这个存储是不可变的。

### [高层次的设计](http://swarm-guide.readthedocs.io/en/latest/architecture.html#id14)

DPA被组织为*DHT（分布式哈希表）*：每个参与节点都有一个地址（由p2p层分解成网络地址）来自与哈希函数范围相同的值集合。特别是它是节点基地帐户的以太坊地址的哈希。

在这个值集上定义了一个*距离度量*，这是一个满足三角不等式的适当度量。总是可以告诉另一个节点或另一个原像对象来自给定的地址或哈希值。与自我的距离为零。

每个节点都有兴趣能够尽可能快地找到哈希值的原始图像，并因此存储尽可能多的原始图像。每个节点最终都会在由可用存储容量限制的给定半径内存储原像对象。密码哈希函数负责随机化和公平的负载平衡。

在高层次上，节点应通过公共网络协议提供以下服务：

- 将新的preimages插入到DPA中
- 从他们自己的存储中检索preimages，如果他们有。
- 将路由信息共享给给定的节点地址

### [要求](http://swarm-guide.readthedocs.io/en/latest/architecture.html#id15)

当接收到本地存储中尚未存在的原像时，该节点将其存储在本地。如果节点为归档分配的存储空间已满，则最长时间访问的对象将被丢弃。请注意，由于下面详述的查找策略，此策略隐含地导致将对象存储在距离节点地址更近的地方，因为 - 所有其他情况相同 - 这些是最有可能从此特定节点请求的对象。

在存储原像之后，存储请求也被转发到路由表的相应行中的所有节点。请注意，kademlia路由可确保节点附近的行实际上包含比自身更远的节点，从而消除存储冗余。

密钥的检索请求最近未见到密钥到达。它在当地商店中查找，如果没有找到，则评估它是否值得拥有，或者其邻近度是否保证其存储。如果认为距离太远，可能会被遗忘，如果在我们的存储半径内，我们会在请求池中打开一个请求条目。在不久的将来请求相同的密钥的其他请求将检查它的状态与此条目。

立即收到请求后，将目标映射到其kademlia邻近区域，并且区域中的同级通过靠近目标进行排序。该请求被转发给第一个连接的对等体。

从POC 0.4开始将实施各种回退策略和并行请求转发。

从第一个向前的设置开始，同一个目标的所有检索请求都会记录在请求池中。如果我们没有收到该窗口内的数据，我们将转到下一个对等点。如果我们在请求的生命周期内没有收到任何交付（它通过内容的传入请求的实时超时保持活动状态），我们认为该项目不存在，甚至可以保留该记录。

在成功检索之后，预存图像被存储并且通过将预图像对象返回到所有请求活动的节点（就活着连接而言并且基于它们的超时感兴趣）或者它们中继或发起请求来回答请求。事实上，这两个并不是必然的区别，它允许准匿名浏览。

然后可以忘记请求节点池，因为所有进一步的查询都可以通过块传递来响应。

意想不到的交付可以被视为存储请求。

如果存储请求第一次出现，我们会评估关键位置，如果认为距离太远可能会被遗忘。如果我们想保留它（这可能是100％，我们只是不转发），然后我们将它保存到永久存储。如果在数据库中找到密钥，则可能会更新其到期日。存储请求被转发到同一个kademlia邻近区域中的对等端。如果我们距离足够近，垃圾箱可能会包含比我们更远离垃圾块的对等设备。

## [同步](http://swarm-guide.readthedocs.io/en/latest/architecture.html#id16)

节点同步是确保内容在查询的地方结束的协议。由于swarm具有基于地址密钥的检索协议，因此内容将从靠近内容地址的一个位（一个邻近位）的节点请求两倍。节点存储的数据由组块的访问数决定：如果我们达到容量，最旧的未访问组块将被删除。一方面，这得益于奖励服务块的奖励系统。这直接转化为一种动机，即内容需要以频率X提供，以便在存储时使您的价值。一方面访问频率直接转化为存储计数。另一方面，它提供了一种方法来结合邻近性和流行度来指示存储的内容。

仅基于距离（所有其他条件相同，假设组块的随机流行度），则可以预期节点将块存储到某个接近半径。但是，始终可以寻找更多足够流行的内容，以便在存储时进行评估。考虑到人气排名的幂律和地块空间中大块的统一分布，人们可以肯定，任何节点都可以扩大他们的存储空间，使其流行度弥补距离。

鉴于受欢迎度的绝对限制，单个基址的存储容量可能存在实际的上限。为了有效利用这种访问容量，应该并行运行多个节点。

此存储协议旨在实现自动缩放弹性云，其中受欢迎度的增长会自动扩展。流行度增加一个数量级将导致更多的节点实际缓存块，导致更少的跳转路由该块，即，更低的延迟恢复。

现在，随着流行程度的增加，最接近目标地址的节点不再有动力保持一个块。如果所有相邻节点都有内容，则检索可能永远不会与最近的节点结束，并且如果它们本身发生不曾检索该内容，则该块将被删除。这就像一个中间有一个洞的面团。正如甜甜圈越来越多，如果有更多的嘴巴咬在它上面，就需要确保它永不断裂，没有外界的询问最终会得到没有它的最近的节点。弹性收缩需要当节点决定删除内容时，它需要将其转发给更靠近块的所有对等点。这实际上是对接收方的指示，后续查询可能最终被发送给他们，因此他们将因其交付而获得奖励。

智能同步是一种分发协议，确保这些传输的发生。除了访问计数，节点用来确定在达到容量时删除哪些内容，块也会存储它们的第一个入口索引。这是一个任意单调递增的索引，并且节点发布它们当前的最高索引，所以实际上它们用作创建的时间戳。该索引有助于保持跟踪与同级同步的内容。

当两个对等体连接时，它们通过在协议握手中交换信息来建立它们的同步状态。当第一次打开对等连接时，syncronisation没有指定索引计数，这意味着相关地址空间中的所有内容（无论多久之前它被输入）都被提供给对等体。默认情况下相关的地址空间只是指定比源更靠近接收节点的所有地址。同步化可以独立进行。一旦达到当前索引的所有内容都被同步，接收方将使用源节点给出的当前索引更新同步化状态。提供计数器的来源应该意味着他们已经为接收者提供了他们所有的时间段。

在实时连接期间所有新存储的内容也被提供给对等体。假设有足够的带宽，对等体预计将完全同步，这意味着接收方存储的关于源的存储计数器不会非常落后于源节点的当前存储计数。

实际上，自对等会话开始以来，内容的所有复制都在会话中持续存在。无论如何，这是需要的，因为传播可能导致连接过载而导致网络缓冲区争用。对于动态响应，传出存储请求流将被缓存。这意味着如果有断开连接，重新连接时会重播先前的积压，即。再次提供给收件人。因此，对于所有意图和目的而言，不需要请求活动连接期间内容的同步。如果接收方更新源的计数器，则在断开连接时，将记录包含此计数器的同步状态。下一次对等体连接收件人会收到存储在此索引和会话开始之间的所有内容。

握手还允许接收者默认地指定地址范围，覆盖所有地址不超过对等者的邻近地址。请注意，对于最接近垃圾桶中的同伴，目标范围可能包含比接收者更接近源的组块。

这里定义的同步协议包含所有推送内容的场景。鉴于所有情况都需要推送块，我们区分5种类型：

- *交货*

  是对检索请求的响应（来自发起者或转发者，本地找到或由其他同伴交付）。传递通常从更靠近目标的节点朝向远离目标的节点进行。

- *传播*

  由于与其他同行同步而推向我们的新内容。传播通常从更远离目标的节点继续到更接近目标的节点。

- *删除*

  如果内容被删除，则内容必须向内推送，即从离目标较远的节点继续到靠近目标的节点。

- *历史*

  狭义同步化促使现有块的延迟传播。从距离目标较远的节点继续到更接近目标的节点。

- *积压*

  是在以前的会议中缓冲的未送达的块

这5种类型大致按照重要性/紧急性的递减顺序排列。该实现允许您为这些类型分配独立的优先级，但强烈建议单调减少优先级。默认情况下，交付优先级高，传播类型中等，积压低优先级。请注意，在该优先级积压内重放保留原始优先级。同样，历史同步的优先级低于实时流量，因此在缺省传播情况下，如果没有实时高优先级或中等优先级块，历史同步只会启动。

为了减少由于接收来自多个来源的组块而导致的网络流量，所有的存储请求都可以通过确认往返进行。对于两个方向上的每个对等连接，源对等方都会发送包含提供给接收方的一批哈希的*未同步密钥*消息。收件人以*传递请求*做出响应，该*请求*还包含接收者实际需要（不具有）传入的未同步密钥中列出的哈希值的一批哈希值。如果没有块丢失，则可能有空的响应。无论何时接收到递送请求都会发送未签发的密钥。如果没有收到超时时间，并且有未解决的内容需要推送，则会发送一个未初始化的密钥消息。

## [同行管理（蜂房，kademlia）](http://swarm-guide.readthedocs.io/en/latest/architecture.html#id17)

Hive是swarm的后勤经理。它使用通用kademlia节点表为任何目标寻找最佳对等列表。这被netstore用来搜索群中的内容。当节点收到对等体建议（bzz协议peersMsgData交换）时，配置单元会将从消息中获得的对等体地址转发给Kademlia表以进行数据库存储和过滤。Hive还管理连接和断开连接，以允许启动并保持路由表的最新状态。当p2p服务器与能够使用bzz协议的节点连接时，配置单元将节点注册到kademlia表中，并发送一个*自我查找*。自查找基本上只是一个检索请求，其目标目标对应于节点的基地址。接收节点不会将自查找记录为请求或转发请求，只需与对等方进行回复即可。这可以通过简单地自动将所有相关联的对等方发送给已连接的对等方来改进。所有发送到连接节点的对等体都被缓存，以便在会话期间不发生重复发送。

### [对等地址](http://swarm-guide.readthedocs.io/en/latest/architecture.html#id18)

网络中的节点由swarm基础帐户的以太坊地址的哈希标识。两个地址之间的距离是其XOR的MSB第一个数值。

### [对数距离和网络拓扑](http://swarm-guide.readthedocs.io/en/latest/architecture.html#id19)

距离度量M小号B （x ，y）中号小号乙（X，ÿ）两个相等长度的字节序列xX一个yÿ是xX的二进制整型转换的值O R yXXØ[Rÿ（按位异或）。二进制转换是大端：最重要的位先（= MSB）。

Př ø X 我中号我吨ÿ（x ，y）P[RØX一世米一世Ťÿ（X，ÿ）是MSB距离的离散对数缩放。它被定义为距离的基数2对数的整数部分的反向等级。它通过计算xX的（MSB）二进制表示中的常见前导零的数量来计算O R yXXØ[Rÿ （0最远，255最近，256自己）。

取相对于固定点x的*邻近顺序*X分类空间中的点（长度为n的字节序列）ñ）分为箱。每个项目至多距离x一半X作为上一个bin中的项目。给定一个均匀分布项目的样本（一个随机序列上的哈希函数），接近度尺度映射到具有负指数尺度基数的一系列子集上。

它还具有这样的属性，即属于同一个容器的任何两个地址彼此距离彼此最多为一半，因为它们来自xX。

如果我们将随机样本中的物品作为连接节点网络中的连接而不是相对邻近度，可以作为图形遍历的本地决策的基础，其中任务是查找两点之间的路线。因为在每一跳中，有限距离减半，只要每个相关的bin都是非空的，对于从另一个节点到达一个节点所需的跳数就有一个保证的恒定的最大限制。

### [对等表格格式](http://swarm-guide.readthedocs.io/en/latest/architecture.html#id20)

对等表由行组成，最初只有一行，最多255个（通常少得多）。每行至多包含kķ对等体（包含关于所述对等体的信息的数据结构，诸如他们的对等体地址，网络地址，时间戳等）。参数kķ称为*桶大小，*并指定为节点配置的一部分。

行编号从0开始。每行编号i一世包含地址与第一个i相匹配的同伴一世该节点地址的位。在我+1一世+1 除了最后一行之外，所有行中的地址位必须与此节点的地址不同。

作为实施的问题，从一开始就可能在内部代表所有255行（要求i+1）一世+1位与所有行中的节点不同）; 但随后考虑到最后的所有行，就好像它们是一行。也就是说，我们在末尾查看空行，并将它们中的元素视为属于第i行一世我在哪里一世是行i中所有元素的总数最低的索引一世在所有更高的行中，一起至多是kķ [[1\]](http://swarm-guide.readthedocs.io/en/latest/architecture.html#id4)。

脚注

| [[1\]](http://swarm-guide.readthedocs.io/en/latest/architecture.html#id3) | 原来的Kademlia论文<http://pdos.csail.mit.edu/~petar/papers/maymounkov-kademlia-lncs.pdf>与此有所不同。高i的行一世对我们来说，这里是低i的行一世在论文中。对我们来说，高我一世意味着高比特数同意，为他们高i一世 意味着高xor距离。 |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
|                                                              |                                                              |

根据其邻近顺序（与基地址相同的地址前缀的长度）将对等体添加到其所属的行。如果这会增加所讨论的行的长度超过桶的大小，则*最坏的*对等体（根据一些，不一定是全局的对等质量度量）将从行中删除，除非它是最后一行。

加入网络只需要一个引导节点，其表中的所有节点都包含在节点的对等表中。此后，它从与索引小于引导节点结束行的行相对应的地址范围执行合成随机地址的查找。

节点仍然可以安全地转储其完整的对等表并接受来自天真节点的连接。覆盖节点的整个对等表需要相当大的计算工作量，即使相对较低的存储桶大小也是如此。针对非天真节点的DoS攻击（如本页所述）需要为每行生成具有相应密钥对的地址，这需要相当多的哈希能力。

### [对等表更新](http://swarm-guide.readthedocs.io/en/latest/architecture.html#id21)

覆盖拓扑（kademlia）应该能够返回一个具有最高优先级的节点记录用于所需的连接。这用于挑选最适合于Swarm的高度连接的低中心性网络结构的最适合Kademlia风格路由选择的活动节点的候选人。

候选人使用以下策略进行选择。我们检查桶中丢失的在线节点是否存在1个最大桶数。在每一轮中，我们从低到高接近顺序桶进行。如果活动节点（=连接的对等体）的数量少于当前轮次，则开始查找已知候选项。确定是否有候选人推荐节点记录数据库行对应的存储桶被检查。如果行光标在位置i上，则选择该行中的第i个元素。如果记录预定在NOW之前不重试，则采用下一个元素。如果记录可以重试，则将其设置为检查，计划检查并返回。下一次检查的时间是NOW + X（持续时间），使得X = ConnRetryExp * delta，其中delta是自上次检查以来的时间，ConnRetryExp是恒定的废弃因子。（请注意，当从对等消息添加节点记录时，它们被标记为检查并放置在光标处，即，优先于较旧的条目）。从节点db行中删除了多于purgeInterval前被选中的条目。如果在全面检查后没有找到候选人，则考虑下一个桶。如果我们到达最大接近度桶时未找到候选人，则下一轮开始。从节点db行中删除了多于purgeInterval前被选中的条目。如果在全面检查后没有找到候选人，则考虑下一个桶。如果我们到达最大接近度桶时未找到候选人，则下一轮开始。从节点db行中删除了多于purgeInterval前被选中的条目。如果在全面检查后没有找到候选人，则考虑下一个桶。如果我们到达最大接近度桶时未找到候选人，则下一轮开始。

节点记录a更喜欢b a>b一个>b 如果a是被动节点（离线过去同伴的记录）

| p- [RøX乙我Ñ（一） | < | p- [RøX乙我Ñ（b） ||p[RØX乙一世ñ（一个）|<|p[RØX乙一世ñ（b）|

|| （proxBin（a）<proxBin（b）&& | proxBin（a）| == | proxBin（b）|）|| （proxBin（a）<proxBin（b）&& | proxBin（a）| == | proxBin（b）|）

|| （proxBin（a）== proxBin（b）&& lastChecked（a）<lastChecked（b））|| （proxBin（a）== proxBin（b）&& lastChecked（a）<lastChecked（b））

这有双重作用。从具有空数据库的幼稚节点开始，这实现了Kademlia自举，并且作为一个成熟的节点，它填补了短线。所有需求。

## [bzz协议](http://swarm-guide.readthedocs.io/en/latest/architecture.html#id22)

BZZ实现了swarm的bzz子协议，有线协议。bzz协议是作为ethereum devp2p系统的子协议实现的。如果BZZ协议处理程序在p2p服务器上注册，则协议实例将由网络层在每个对等方上启动。

该协议负责实际传送bzz协议编码和解码请求以进行存储和检索，处理与Netstore处理DHT逻辑的协议握手信息，通过配置单元逻辑管理器注册Kademlia表中的对等设备。

注意

随着路线图上的组件得到实施并且协议解决，bzz协议正在变得不稳定，将提供详细的有线协议规范

## [Incentivisation](http://swarm-guide.readthedocs.io/en/latest/architecture.html#id23)

### [交换，发誓和诈骗](http://swarm-guide.readthedocs.io/en/latest/architecture.html#id24)

### [SWAP - Swarm Accounting Protocol](http://swarm-guide.readthedocs.io/en/latest/architecture.html#id25)

Swarm Accounting Protocol，使用自动付款进行保护

### [SWEAR - 具有强制存档规则或swarm执行和注册的存储](http://swarm-guide.readthedocs.io/en/latest/architecture.html#id26)

### [SWINDLE - 由INSUANCE存款诉讼和托管担保](http://swarm-guide.readthedocs.io/en/latest/architecture.html#id27)

[ 以前](http://swarm-guide.readthedocs.io/en/latest/usage.html)
